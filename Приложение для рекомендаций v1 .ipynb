{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "5e7d8de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics import jaccard_score\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import Word2Vec\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "4771a42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Victoria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Victoria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Victoria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Victoria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import gensim.downloader as download_api\n",
    "russian_model = download_api.load('word2vec-ruscorpora-300')\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.fasttext import FastText\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "!pip install pymorphy2 > None\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import re\n",
    "import pandas as pd\n",
    "import pymorphy2\n",
    "from nltk.stem.snowball import RussianStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from string import punctuation\n",
    "nltk.download('stopwords')\n",
    "from  sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from  sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "from nltk import wordpunct_tokenize, WordNetLemmatizer, sent_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords as sw, wordnet as wn\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import string\n",
    "import re\n",
    "punctuations = list(punctuation)\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('russian')\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt')\n",
    "tfidf_encoder = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "b72a1b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_vacancy</th>\n",
       "      <th>название вакансии</th>\n",
       "      <th>дата публикации</th>\n",
       "      <th>компания</th>\n",
       "      <th>уровень зарплаты</th>\n",
       "      <th>URL</th>\n",
       "      <th>описание вакансии</th>\n",
       "      <th>адрес</th>\n",
       "      <th>тип занятости</th>\n",
       "      <th>описание вакансии_tokenized</th>\n",
       "      <th>...</th>\n",
       "      <th>Low_salary</th>\n",
       "      <th>High_salary</th>\n",
       "      <th>Type_employee</th>\n",
       "      <th>Work_time</th>\n",
       "      <th>experience</th>\n",
       "      <th>Duties_unch</th>\n",
       "      <th>Skills_unch</th>\n",
       "      <th>описание_unch</th>\n",
       "      <th>Demands_unch</th>\n",
       "      <th>company_sphere</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Инженер-конструктор</td>\n",
       "      <td>24 ноября 2023 в Санкт-Петербурге</td>\n",
       "      <td>ООО Русь-Турбо</td>\n",
       "      <td>от 70 000 до 120 000 ₽ на руки</td>\n",
       "      <td>https://murmansk.hh.ru/vacancy/87418369?from=v...</td>\n",
       "      <td>Обязанности: Разработка и проектирование запча...</td>\n",
       "      <td>Санкт-Петербург</td>\n",
       "      <td>Полная занятость, полный день</td>\n",
       "      <td>['обязанность', 'разработка', 'проектирование'...</td>\n",
       "      <td>...</td>\n",
       "      <td>70000</td>\n",
       "      <td>70000</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>полный день</td>\n",
       "      <td>1.0</td>\n",
       "      <td>запчасть оснастка приспособление паровой турби...</td>\n",
       "      <td>3d ansys самоорганизация дисциплина коммуникаб...</td>\n",
       "      <td>обязанность разработка проектирование запчасть...</td>\n",
       "      <td>выпуск конструкторский 3d ansys самоорганизаци...</td>\n",
       "      <td>Инженерно-техническая</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Инженер-конструктор</td>\n",
       "      <td>22 ноября 2023 в Санкт-Петербурге</td>\n",
       "      <td>ГРУППА КОМПАНИЙ БАЗИС</td>\n",
       "      <td>от 80 000 до 110 000 ₽ на руки</td>\n",
       "      <td>https://murmansk.hh.ru/vacancy/88536853?from=v...</td>\n",
       "      <td>Группа компаний Базис — крупная многопрофильна...</td>\n",
       "      <td>Санкт-Петербург</td>\n",
       "      <td>Полная занятость, полный день</td>\n",
       "      <td>['группа', 'компания', 'базис', '—', 'крупный'...</td>\n",
       "      <td>...</td>\n",
       "      <td>80000</td>\n",
       "      <td>80000</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>полный день</td>\n",
       "      <td>1.0</td>\n",
       "      <td>довести идеальный конструктивный стадия здание...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>группа компания базис — крупный многопрофильны...</td>\n",
       "      <td>профессионализм гк базис удаться сформировать ...</td>\n",
       "      <td>Другое</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_vacancy    название вакансии                    дата публикации  \\\n",
       "0           1  Инженер-конструктор  24 ноября 2023 в Санкт-Петербурге   \n",
       "1           2  Инженер-конструктор  22 ноября 2023 в Санкт-Петербурге   \n",
       "\n",
       "                компания                уровень зарплаты  \\\n",
       "0         ООО Русь-Турбо  от 70 000 до 120 000 ₽ на руки   \n",
       "1  ГРУППА КОМПАНИЙ БАЗИС  от 80 000 до 110 000 ₽ на руки   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://murmansk.hh.ru/vacancy/87418369?from=v...   \n",
       "1  https://murmansk.hh.ru/vacancy/88536853?from=v...   \n",
       "\n",
       "                                   описание вакансии            адрес  \\\n",
       "0  Обязанности: Разработка и проектирование запча...  Санкт-Петербург   \n",
       "1  Группа компаний Базис — крупная многопрофильна...  Санкт-Петербург   \n",
       "\n",
       "                   тип занятости  \\\n",
       "0  Полная занятость, полный день   \n",
       "1  Полная занятость, полный день   \n",
       "\n",
       "                         описание вакансии_tokenized  ... Low_salary  \\\n",
       "0  ['обязанность', 'разработка', 'проектирование'...  ...      70000   \n",
       "1  ['группа', 'компания', 'базис', '—', 'крупный'...  ...      80000   \n",
       "\n",
       "  High_salary     Type_employee     Work_time experience  \\\n",
       "0       70000  Полная занятость   полный день        1.0   \n",
       "1       80000  Полная занятость   полный день        1.0   \n",
       "\n",
       "                                         Duties_unch  \\\n",
       "0  запчасть оснастка приспособление паровой турби...   \n",
       "1  довести идеальный конструктивный стадия здание...   \n",
       "\n",
       "                                         Skills_unch  \\\n",
       "0  3d ansys самоорганизация дисциплина коммуникаб...   \n",
       "1                                                NaN   \n",
       "\n",
       "                                       описание_unch  \\\n",
       "0  обязанность разработка проектирование запчасть...   \n",
       "1  группа компания базис — крупный многопрофильны...   \n",
       "\n",
       "                                        Demands_unch         company_sphere  \n",
       "0  выпуск конструкторский 3d ansys самоорганизаци...  Инженерно-техническая  \n",
       "1  профессионализм гк базис удаться сформировать ...                 Другое  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"df_vacancies2.xlsx\"\n",
    "df_vacancies = pd.read_excel(file_path)\n",
    "df_vacancies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "7546c352",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_vacancies\n",
    "city_filter = 'Москва'\n",
    "desired_salary_filter = 50000\n",
    "responsibilities_filter = 'Аналитик'\n",
    "\n",
    "\n",
    "df_filtered = df[(df['адрес'] == city_filter) &\n",
    "                 (df['Low_salary'] >= desired_salary_filter) &\n",
    "                 (df['название вакансии'].str.contains(responsibilities_filter, case=False))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "7893f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered[['описание_unch','адрес','Duties_unch','High_salary','тип занятости','название вакансии','описание вакансии','Skills_unch','URL','company_sphere']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "9541f249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "vacancy_descriptions = [desc.split() for desc in df_filtered['описание_unch']]\n",
    "word2vec_model = Word2Vec(sentences=vacancy_descriptions, vector_size=10000, window=5, min_count=1, sg=2)\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "34c1eaa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   название вакансии                                  описание вакансии  \\\n",
       " 25          Аналитик  Добрый день Уважаемый соискатель! Мы динамично...   \n",
       " 29          Аналитик  Обязанности: Аналитическая поддержка департаме...   \n",
       " 33          Аналитик  Обязанности: Координация проекта (сроков испол...   \n",
       " 35          Аналитик  Инвестиционная группа КРИГА – динамично растущ...   \n",
       " 49  Стартап-Аналитик  Обязанности: • Написание бизнес-планов и созда...   \n",
       " \n",
       "                                                   URL  \n",
       " 25  https://murmansk.hh.ru/vacancy/88848915?from=v...  \n",
       " 29  https://murmansk.hh.ru/vacancy/89450342?from=v...  \n",
       " 33  https://murmansk.hh.ru/vacancy/89831486?from=v...  \n",
       " 35  https://murmansk.hh.ru/vacancy/89662014?from=v...  \n",
       " 49  https://murmansk.hh.ru/vacancy/89516749?from=v...  ,\n",
       " [0.56, 0.56, 0.56, 0.56, 0.56])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "vacancy_descriptions = [desc.split() for desc in df_filtered['описание_unch']]\n",
    "word2vec_model = Word2Vec(sentences=vacancy_descriptions, vector_size=10000, window=5, min_count=1, sg=2)\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "def recommendations(resume_text, skills, word2vec_model=word2vec_model, bert_model=bert_model, bert_tokenizer=bert_tokenizer):\n",
    "    resume_embeddings = [word2vec_model.wv[word] for word in resume_text.split() if word in word2vec_model.wv]\n",
    "    skills_embeddings = [word2vec_model.wv[word] for word in skills.split() if word in word2vec_model.wv]\n",
    "\n",
    "    resume_mean = np.mean(resume_embeddings, axis=0) if resume_embeddings else np.zeros(word2vec_model.vector_size)\n",
    "    skills_mean = np.mean(skills_embeddings, axis=0) if skills_embeddings else np.zeros(word2vec_model.vector_size)\n",
    "\n",
    "    # Convert resume text and skills to BERT embeddings\n",
    "    resume_bert_input = bert_tokenizer(resume_text, padding=True, truncation=True, return_tensors='pt')\n",
    "    skills_bert_input = bert_tokenizer(skills, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        resume_output = bert_model(**resume_bert_input).last_hidden_state.mean(dim=1)\n",
    "        skills_output = bert_model(**skills_bert_input).last_hidden_state.mean(dim=1)\n",
    "\n",
    "    # Compute the cosine similarity between the embeddings\n",
    "    resume_similarities_word2vec = [np.dot(word2vec_model.wv[key], resume_mean) for key in word2vec_model.wv.key_to_index.keys() if key in word2vec_model.wv.key_to_index]\n",
    "    skills_similarities_word2vec = [np.dot(word2vec_model.wv[key], skills_mean) for key in word2vec_model.wv.key_to_index.keys() if key in word2vec_model.wv.key_to_index]\n",
    "\n",
    "    resume_similarities_bert = torch.nn.functional.cosine_similarity(resume_output, resume_output).item()\n",
    "    skills_similarities_bert = torch.nn.functional.cosine_similarity(skills_output, skills_output).item()\n",
    "\n",
    "    # Combine the similarities using a weighted average\n",
    "    resume_similarities = [(a + resume_similarities_bert) / 2 for a in resume_similarities_word2vec]\n",
    "    skills_similarities = [(b + skills_similarities_bert) / 2 for b in skills_similarities_word2vec]\n",
    "\n",
    "    # Sort the similarities in descending order\n",
    "    resume_similarity_scores = sorted(enumerate(resume_similarities), key=lambda x: x[1], reverse=True)\n",
    "    skills_similarity_scores = sorted(enumerate(skills_similarities), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the top 5 most similar vacancies for both resume and skills\n",
    "    resume_similarity_scores = resume_similarity_scores[:5]\n",
    "    skills_similarity_scores = skills_similarity_scores[:5]\n",
    "\n",
    "    # Combine and return the top 5 most similar vacancies\n",
    "    similarity_scores_combined = [(a + b) for a, b in zip(resume_similarity_scores, skills_similarity_scores)]\n",
    "    vacancy_index_combined = [i[0] for i in similarity_scores_combined]\n",
    "\n",
    "    acceptance_prob_combined = [i[1]*1.12 for i in similarity_scores_combined]\n",
    "\n",
    "    return df_filtered[['название вакансии', 'описание вакансии','URL']].iloc[vacancy_index_combined], acceptance_prob_combined\n",
    "\n",
    "recommendations(' В рамках работы занимаюсь: проведением A/B тестов маркетинговых кампаний, исследованием в области клиентского опыта', 'SQL  маркетинг')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3932b7e",
   "metadata": {},
   "source": [
    "Добавление модели Маккола в рекомендательную сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "c15f1af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_resume</th>\n",
       "      <th>id_vacancy</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3856</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1242</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_resume  id_vacancy  rating\n",
       "0          1        3856       1\n",
       "1          1        1242       1"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"ratings_df.xlsx\"\n",
    "df_ratings = pd.read_excel(file_path)\n",
    "df_ratings.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "a11da0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company_sphere\n",
      "IT                       0.117409\n",
      "Банки IT финансы         0.167135\n",
      "Государственная сфера    0.146611\n",
      "Другое                   0.137500\n",
      "ИП                       0.113350\n",
      "Инженерно-техническая    0.129797\n",
      "Консалтинг               0.058824\n",
      "Розничная торговля       0.052632\n",
      "Телеком                  0.135135\n",
      "Торговля                 0.158402\n",
      "Туризм                   0.095238\n",
      "Юридические фирмы        0.000000\n",
      "Name: rating, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_merged = pd.merge(df_vacancies, df_ratings, on='id_vacancy', how='outer').fillna(0)\n",
    "alpha = df_merged.groupby('company_sphere')['rating'].agg(lambda x: sum(x > 1) / len(x))\n",
    "print(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "1d89a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['betta'] = df_merged['company_sphere'].apply(lambda x: 0.167135 if x == 'Банки IT финансы' else (\n",
    "                                                  0.117409 if x == 'IT' else (\n",
    "                                                  0.113350 if x == 'ИП' else (\n",
    "                                                  0.129797 if x == 'Инженерно-техническая' else (\n",
    "                                                  0.137500 if x == 'Другое' else (\n",
    "                                                  0.052632 if x == 'Розничная торговля' else (\n",
    "                                                  0.058824 if x == 'Консалтинг' else (\n",
    "                                                  0.135135 if x == 'Телеком' else (\n",
    "                                                  0.158402 if x == 'Торговля' else 0\n",
    ")))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "97c1e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lognormal_draws(n=len(df_merged['company_sphere']), μ=np.mean(df_merged['Low_salary']), σ=50000, seed=1234):\n",
    "    np.random.seed(seed)\n",
    "    z = np.random.randn(n)\n",
    "    w_draws = np.exp(μ + σ * z)\n",
    "    return w_draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "065854f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reservation_wage(mcm):\n",
    "    \"\"\"\n",
    "    Computes the reservation wage of an instance of the McCall model\n",
    "    by finding the smallest w such that v(w) >= h.\n",
    "\n",
    "    If no such w exists, then w_bar is set to np.inf.\n",
    "    \"\"\"\n",
    "    u = lambda x: np.log(x/2)\n",
    "\n",
    "    v, d = solve_model(mcm)\n",
    "    h = u(mcm.c) + mcm.β * d\n",
    "\n",
    "    w_bar = np.inf\n",
    "    for i, wage in enumerate(mcm.w_grid):\n",
    "        if v[i] > h:\n",
    "            w_bar = wage\n",
    "            break\n",
    "\n",
    "    return w_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "51c7cca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lognormal_draws(n=len(df_merged['company_sphere']), μ=np.mean(df_merged['Low_salary']), σ=0.009, seed=1234):\n",
    "    z = df_merged['betta']\n",
    "    w_draws = np.exp(μ + σ * z)\n",
    "    return w_draws\n",
    "\n",
    "class McCallModelContinuous:\n",
    "    def __init__(self, c=1, α=0.1, β=0.96, grid_min=1e-10, grid_max=5, grid_size=len(df_merged), w_draws=None, σ=5000):\n",
    "        self.c, self.α, self.β = c, α, β\n",
    "        self.w_grid = np.linspace(grid_min, grid_max, grid_size)\n",
    "      \n",
    "        if w_draws is None:\n",
    "            self.w_draws = lognormal_draws(len(self.w_grid), np.mean(self.w_grid), σ)\n",
    "        else:\n",
    "            self.w_draws = w_draws\n",
    "    \n",
    "    def update(self, mcm):\n",
    "        c, α, β = self.c, self.α, self.β\n",
    "        w = self.w_grid\n",
    "        u = lambda x: np.log(x)\n",
    "\n",
    "        vf = lambda x: np.interp(x, w, mcm)\n",
    "\n",
    "        d_new = np.mean(np.maximum(vf(self.w_draws), u(c) + β * mcm))\n",
    "\n",
    "        v_new = u(w) + β * ((1 - α) * mcm + α * d_new)\n",
    "\n",
    "        return v_new, d_new\n",
    "\n",
    "def compute_reservation_wage(mcm):\n",
    "    u = lambda x: np.log(x/2)\n",
    "\n",
    "    v, d = mcm.update(mcm)\n",
    "    h = u(mcm.c) + mcm.β * d\n",
    "\n",
    "    w_bar = 0\n",
    "    for i, wage in enumerate(mcm.w_grid):\n",
    "        if v[i] >= h:\n",
    "            w_bar = wage\n",
    "            break\n",
    "\n",
    "    return w_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "317fcc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем экземпляр модели и вычисляем резервные зарплаты\n",
    "df_merged['reservation_wage'] = np.random.normal(df_merged['Low_salary'].mean(), 20000 * df_merged['betta'] * 0.96, len(df_merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "2894260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df= df_merged\n",
    "city_filter = 'Москва'\n",
    "desired_salary_filter = 50000\n",
    "responsibilities_filter = 'Аналитик'\n",
    "\n",
    "df_filtered = df[(df['адрес'] == city_filter) &\n",
    "                 (df['Low_salary'] >= desired_salary_filter) &\n",
    "                 (df['название вакансии'].str.contains(responsibilities_filter, case=False))]\n",
    "vacancy_descriptions = [str(desc).split() for desc in df_filtered['описание_unch']]\n",
    "word2vec_model = Word2Vec(sentences=vacancy_descriptions, vector_size=10000, window=5, min_count=1, sg=2)\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "18ef4e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victoria\\AppData\\Local\\Temp/ipykernel_4700/2195022121.py:32: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  macallum_probabilities = 1 - (df_filtered['betta'].values / (df_filtered['Low_salary'].values / df_filtered['reservation_wage'].values * np.mean(resume_similarities)))\n",
      "C:\\Users\\Victoria\\AppData\\Local\\Temp/ipykernel_4700/2195022121.py:32: RuntimeWarning: invalid value encountered in true_divide\n",
      "  macallum_probabilities = 1 - (df_filtered['betta'].values / (df_filtered['Low_salary'].values / df_filtered['reservation_wage'].values * np.mean(resume_similarities)))\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "df_filtered = df_merged\n",
    "def recommendations(resume_text, skills, word2vec_model=word2vec_model, bert_model=bert_model, bert_tokenizer=bert_tokenizer):\n",
    "    resume_embeddings = [word2vec_model.wv[word] for word in resume_text.split() if word in word2vec_model.wv]\n",
    "    skills_embeddings = [word2vec_model.wv[word] for word in skills.split() if word in word2vec_model.wv]\n",
    "\n",
    "    resume_mean = np.mean(resume_embeddings, axis=0) if resume_embeddings else np.zeros(word2vec_model.vector_size)\n",
    "    skills_mean = np.mean(skills_embeddings, axis=0) if skills_embeddings else np.zeros(word2vec_model.vector_size)\n",
    "\n",
    "    # Convert resume text and skills to BERT embeddings\n",
    "    resume_bert_input = bert_tokenizer(resume_text, padding=True, truncation=True, return_tensors='pt')\n",
    "    skills_bert_input = bert_tokenizer(skills, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        resume_output = bert_model(**resume_bert_input).last_hidden_state.mean(dim=1)\n",
    "        skills_output = bert_model(**skills_bert_input).last_hidden_state.mean(dim=1)\n",
    "\n",
    "    # Compute the cosine similarity between the embeddings\n",
    "    resume_similarities_word2vec = [np.dot(word2vec_model.wv[key], resume_mean) for key in word2vec_model.wv.key_to_index.keys() if key in word2vec_model.wv.key_to_index]\n",
    "    skills_similarities_word2vec = [np.dot(word2vec_model.wv[key], skills_mean) for key in word2vec_model.wv.key_to_index.keys() if key in word2vec_model.wv.key_to_index]\n",
    "\n",
    "    resume_similarities_bert = torch.nn.functional.cosine_similarity(resume_output, resume_output).item()\n",
    "    skills_similarities_bert = torch.nn.functional.cosine_similarity(skills_output, skills_output).item()\n",
    "\n",
    "    # Combine the similarities using a weighted average\n",
    "    resume_similarities = [(a + resume_similarities_bert) / 2 for a in resume_similarities_word2vec]\n",
    "    skills_similarities = [(b + skills_similarities_bert) / 2 for b in skills_similarities_word2vec]\n",
    "    # Calculate the MacCallum probability\n",
    "    macallum_probabilities = 1 - (df_filtered['betta'].values / (df_filtered['Low_salary'].values / df_filtered['reservation_wage'].values * np.mean(resume_similarities)))\n",
    "\n",
    "    # Sort the MacCallum probabilities in descending order\n",
    "    macallum_scores = sorted(enumerate(macallum_probabilities), key=lambda x: x[1], reverse=True)\n",
    "    resume_similarity_scores = sorted(enumerate(resume_similarities), key=lambda x: x[1], reverse=True)\n",
    "    skills_similarity_scores = sorted(enumerate(skills_similarities), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the top 5 most similar vacancies for both resume and skills\n",
    "    resume_similarity_scores = resume_similarity_scores[:5]\n",
    "    skills_similarity_scores = skills_similarity_scores[:5]\n",
    "    macallum_scores = macallum_scores[:5]\n",
    "    df_filtered['macallum_scores']=macallum_probabilities\n",
    "\n",
    "    # Combine and return the top 5 most similar vacancies\n",
    "    similarity_scores_combined = [(a + b) for a, b in zip(resume_similarity_scores, skills_similarity_scores)]\n",
    "    vacancy_index_combined = [i[0] for i in similarity_scores_combined]\n",
    "    top_vacancy_index_macallum = [i[0] for i in macallum_scores]\n",
    "    acceptance_prob_combined = [i[1]*1.12 for i in similarity_scores_combined]\n",
    "    top_vacancy_prob_macallum = [i[1] for i in macallum_scores]\n",
    "\n",
    "    return df_filtered[['название вакансии', 'описание вакансии','URL','macallum_scores']].iloc[vacancy_index_combined]\n",
    "t = recommendations(' В рамках работы занимаюсь: проведением A/B тестов маркетинговых кампаний, исследованием в области клиентского опыта', 'g')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "420f5291",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_filtered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_31288/1829606303.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_filtered\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_filtered' is not defined"
     ]
    }
   ],
   "source": [
    "df_filtered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f60758c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "6709111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tkinter.ttk import Combobox\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import ImageTk, Image\n",
    "import codecs\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, messagebox, filedialog\n",
    "import time\n",
    "from tkinter.ttk import Combobox\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import ImageTk, Image\n",
    "import codecs\n",
    "import torch\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox, filedialog\n",
    "import time\n",
    "from tkinter.ttk import Combobox\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import ImageTk, Image\n",
    "import codecs\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, messagebox, filedialog\n",
    "import time\n",
    "from tkinter.ttk import Combobox\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import ImageTk, Image\n",
    "import codecs\n",
    "import torch\n",
    "\n",
    "win = tk.Tk()\n",
    "win.geometry('400x400')\n",
    "win.title(\"Job Recommender\")\n",
    "entries = []\n",
    "for i, label in enumerate(labels):\n",
    "    tk.Label(win, text=label).grid(row=i, column=0)\n",
    "    entry = tk.Entry(win)\n",
    "    entry.grid(row=i, column=1)\n",
    "    entries.append(entry)\n",
    "\n",
    "def upload_resume():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Text files\", \"*.txt\")])\n",
    "    if file_path:\n",
    "        with codecs.open(file_path, 'r', encoding='utf-8') as file:\n",
    "            resume_text = file.read()\n",
    "        if len(entries) > 1:  # Check if entries list has at least two elements\n",
    "            entries[1].insert(0, resume_text)\n",
    "        else:\n",
    "            messagebox.showerror(\"Index Error\", \"Entries list index out of bounds.\")\n",
    "\n",
    "upload_button = tk.Button(win, text=\"Upload Resume\", command=upload_resume)\n",
    "upload_button.grid(row=1, column=2)\n",
    "\n",
    "start_button = tk.Button(win, text=\"Start\", command=lambda: start_recommendation(entries))\n",
    "start_button.grid(row=len(labels), column=1)\n",
    "df_filtered = df_filtered.loc[:,~df_filtered.columns.duplicated()]\n",
    "df = df.loc[:,~df.columns.duplicated()]\n",
    "\n",
    "def recommendations(resume_text, skills, word2vec_model=word2vec_model, bert_model=bert_model, bert_tokenizer=bert_tokenizer):\n",
    "    resume_embeddings = [word2vec_model.wv[word] for word in resume_text.split() if word in word2vec_model.wv]\n",
    "    skills_embeddings = [word2vec_model.wv[word] for word in skills.split() if word in word2vec_model.wv]\n",
    "\n",
    "    resume_mean = np.mean(resume_embeddings, axis=0) if resume_embeddings else np.zeros(word2vec_model.vector_size)\n",
    "    skills_mean = np.mean(skills_embeddings, axis=0) if skills_embeddings else np.zeros(word2vec_model.vector_size)\n",
    "\n",
    "    # Convert resume text and skills to BERT embeddings\n",
    "    resume_bert_input = bert_tokenizer(resume_text, padding=True, truncation=True, return_tensors='pt')\n",
    "    skills_bert_input = bert_tokenizer(skills, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        resume_output = bert_model(**resume_bert_input).last_hidden_state.mean(dim=1)\n",
    "        skills_output = bert_model(**skills_bert_input).last_hidden_state.mean(dim=1)\n",
    "\n",
    "    # Compute the cosine similarity between the embeddings\n",
    "    resume_similarities_word2vec = [np.dot(word2vec_model.wv[key], resume_mean) for key in word2vec_model.wv.key_to_index.keys() if key in word2vec_model.wv.key_to_index]\n",
    "    skills_similarities_word2vec = [np.dot(word2vec_model.wv[key], skills_mean) for key in word2vec_model.wv.key_to_index.keys() if key in word2vec_model.wv.key_to_index]\n",
    "\n",
    "    resume_similarities_bert = torch.nn.functional.cosine_similarity(resume_output, resume_output).item()\n",
    "    skills_similarities_bert = torch.nn.functional.cosine_similarity(skills_output, skills_output).item()\n",
    "\n",
    "    # Combine the similarities using a weighted average\n",
    "    resume_similarities = [(a + resume_similarities_bert) / 2 for a in resume_similarities_word2vec]\n",
    "    skills_similarities = [(b + skills_similarities_bert) / 2 for b in skills_similarities_word2vec]\n",
    "    # Calculate the MacCallum probability\n",
    "    \n",
    "    # Sort the MacCallum probabilities in descending order\n",
    "    resume_similarity_scores = sorted(enumerate(resume_similarities), key=lambda x: x[1], reverse=True)\n",
    "    skills_similarity_scores = sorted(enumerate(skills_similarities), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the top 5 most similar vacancies for both resume and skills\n",
    "    resume_similarity_scores = resume_similarity_scores[:5]\n",
    "    skills_similarity_scores = skills_similarity_scores[:5]\n",
    "\n",
    "    # Combine and return the top 5 most similar vacancies\n",
    "    similarity_scores_combined = [(a + b) for a, b in zip(resume_similarity_scores, skills_similarity_scores)]\n",
    "    vacancy_index_combined = [i[0] for i in similarity_scores_combined]\n",
    "    acceptance_prob_combined = [i[1]*1.12 for i in similarity_scores_combined]\n",
    "\n",
    "    return df_filtered[['название вакансии', 'описание вакансии','URL','macallum_scores']].iloc[vacancy_index_combined]                           \n",
    "    pass\n",
    "                                \n",
    "def export_recommendations(recommended_jobs):\n",
    "    file_path = filedialog.asksaveasfilename(defaultextension=\".xlsx\", filetypes=[(\"Excel files\", \"*.xlsx\")])\n",
    "    if file_path:\n",
    "        recommended_jobs.to_excel(file_path, index=False)\n",
    "\n",
    "def start_recommendation(entries):\n",
    "    global df_filtered\n",
    "    user_input = [entry.get() for entry in entries]\n",
    "\n",
    "    if len(user_input) < 7:\n",
    "        messagebox.showerror(\"Input Error\", \"Please fill in all required fields.\")\n",
    "        return\n",
    "\n",
    "    city_filter = user_input[3]\n",
    "    salary = int(user_input[4])\n",
    "    Position = user_input[0]\n",
    "    Employment_Type = user_input[5]\n",
    "    Experience = int(user_input[6])\n",
    "\n",
    "    if city_filter and salary and Position and Employment_Type:\n",
    "        df_filtered = df[(df['адрес'] == city_filter) & \n",
    "                         (df['Low_salary'] >= salary) & \n",
    "                         (df['experience'] >= Experience) &\n",
    "                         (df['experience'] <= Experience+1) &\n",
    "                         (df['название вакансии'].str.contains(Position, case=False))]\n",
    "        df_filtered = df_filtered[['описание_unch', 'адрес',  'Low_salary', 'тип занятости', 'название вакансии', 'описание вакансии', 'Skills_unch', 'URL','experience','betta','reservation_wage','Low_salary','macallum_scores']]\n",
    "        \n",
    "        # Call the recommendations function and display results\n",
    "        recommended_jobs = recommendations(user_input[1], user_input[2])\n",
    "        recommended_jobs['описание вакансии'] = recommended_jobs['описание вакансии'].str.slice(0, 600) + '...'\n",
    "        recommended_jobs = recommended_jobs[['название вакансии', 'описание вакансии', 'URL','macallum_scores']].head(5)\n",
    "\n",
    "        # Export recommendations to Excel\n",
    "        export_recommendations(recommended_jobs)\n",
    "\n",
    "        new_win = tk.Toplevel(win)\n",
    "        table = ttk.Treeview(new_win, columns=(\"название вакансии\", \"описание вакансии\", \"URL\",\"macallum_scores\"), show=\"headings\")\n",
    "        table.heading(\"название вакансии\", text=\"название вакансии\")\n",
    "        table.heading(\"описание вакансии\", text=\"описание вакансии\")\n",
    "        table.heading(\"URL\", text=\"ссылка на вакансию\")\n",
    "        table.heading(\"macallum_scores\", text=\"Вероятность\")\n",
    "        for index, row in recommended_jobs.iterrows():\n",
    "            table.insert(\"\", \"end\", values=(row['название вакансии'], row['описание вакансии'], row['URL'], row['macallum_scores']))\n",
    "        table.pack()\n",
    "        table.column(\"название вакансии\", width=200)\n",
    "        table.column(\"описание вакансии\", width=400)\n",
    "        table.column(\"URL\", width=800)\n",
    "        table.column(\"Вероятность\", width=800)\n",
    "    else:\n",
    "        messagebox.showerror(\"Input Error\", \"Please provide valid input for all fields.\")    \n",
    "        return\n",
    "win.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "3e087c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    70000\n",
       "1    70000\n",
       "2    70000\n",
       "3    70000\n",
       "4    80000\n",
       "Name: Low_salary, dtype: int64"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['Low_salary'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "11921e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Position',\n",
       " 'Your resume:',\n",
       " 'Skills',\n",
       " 'City',\n",
       " 'Desired Salary (from)',\n",
       " 'Employment_Type',\n",
       " 'Experience']"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e933607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
